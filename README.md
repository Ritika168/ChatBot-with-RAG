**ğŸ§  Chatbot with RAG (Retrieval-Augmented Generation)**

An intelligent AI chatbot built using LangChain, OpenAI, and Streamlit, capable of answering questions based on custom PDF documents.
This project uses RAG (Retrieval-Augmented Generation) to combine vector-based document retrieval with LLM reasoning for accurate, context-aware responses.

**ğŸš€ Features**

ğŸ—‚ï¸ Upload or use local PDF files as knowledge sources

ğŸ§© Automatically chunk and embed document text

ğŸ§  Retrieve relevant information using vector search

ğŸ’¬ Conversational question-answering interface (via Streamlit UI)

âš¡ Powered by LangChain, HuggingFace embeddings, and FAISS/ChromaDB

**ğŸ§° Tech Stack**

| Component | Technology |
|------------|-------------|
| **Language** | Python 3.9+ |
| **Frontend** | Streamlit |
| **LLM Framework** | LangChain |
| **Embeddings** | HuggingFace (`all-MiniLM-L12-v2`) |
| **Vector Database** | ChromaDB |
| **PDF Loader** | LangChainâ€™s `PyPDFLoader` |
| **Environment** | Virtualenv / Pipenv |

**ğŸ—ï¸ Project Structure**


Chatbot-with-RAG<br>
â”‚<br>
â”œâ”€â”€ phase_1.py                 # Main Streamlit chatbot app<br>
â”œâ”€â”€ data/                      # Folder to store your PDF files<br>
â”‚   â””â”€â”€ example.pdf<br>
â”œâ”€â”€ Pipfile / requirements.txt # Dependencies (auto-generated by pipenv)<br>
â”œâ”€â”€ README.md                  # Project documentation<br>
â””â”€â”€ .env                       # Your environment variables (API keys)<br>


**âš™ï¸ Setup Instructions**<br>


**1ï¸âƒ£ Clone the Repository**<br>

git clone https://github.com/Ritika168/ChatBot-with-RAG.git

cd ChatBot-with-RAG

**2ï¸âƒ£ Create Virtual Environment**

You can use either pipenv or venv.

Option A (Pipenv):

pip install pipenv
pipenv install
pipenv shell

Option B (venv):

python -m venv venv
venv\Scripts\activate     # for Windows
source venv/bin/activate  # for macOS/Linux
pip install -r requirements.txt<br>

**3ï¸âƒ£ Add Your PDF**

Place your reference PDF inside the project folder or create a /data directory:

Chatbot-with-RAG/data/your_document.pdf


Update the path in phase_1.py:

pdf_name = "./data/your_document.pdf"<br>

**4ï¸âƒ£ Add Your OpenAI API Key**

Create a .env file in the root directory:

OPENAI_API_KEY=your_api_key_here<br>

**â–¶ï¸ Run the App**

Once setup is done, launch Streamlit:

streamlit run phase_1.py

The chatbot interface will open in your browser (usually at):

http://localhost:8501<br>


**ğŸ“¦ Dependencies**

Major libraries used:

streamlit
langchain
langchain-core
langchain-community
langgraph
chromadb
faiss-cpu
tiktoken
openai
pypdf
pandas
numpy
torch
transformers<br>

**ğŸ’¡ How It Works**

PDF Loading â€“ The chatbot reads and extracts text using PyPDFLoader.

Text Chunking â€“ Splits text into chunks for vector embedding.

Vectorization â€“ Converts chunks into embeddings using HuggingFace models.

Storage â€“ Stores embeddings in a ChromaDB (vector database).

Retrieval + Generation (RAG) â€“ When you ask a question, it retrieves the top relevant chunks and sends them to the LLM to generate a context-aware answer.

