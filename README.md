**🧠 Chatbot with RAG (Retrieval-Augmented Generation)**

An intelligent AI chatbot built using LangChain, OpenAI, and Streamlit, capable of answering questions based on custom PDF documents.
This project uses RAG (Retrieval-Augmented Generation) to combine vector-based document retrieval with LLM reasoning for accurate, context-aware responses.

**🚀 Features**

🗂️ Upload or use local PDF files as knowledge sources

🧩 Automatically chunk and embed document text

🧠 Retrieve relevant information using vector search

💬 Conversational question-answering interface (via Streamlit UI)

⚡ Powered by LangChain, HuggingFace embeddings, and FAISS/ChromaDB

**🧰 Tech Stack**

| Component | Technology |
|------------|-------------|
| **Language** | Python 3.9+ |
| **Frontend** | Streamlit |
| **LLM Framework** | LangChain |
| **Embeddings** | HuggingFace (`all-MiniLM-L12-v2`) |
| **Vector Database** | ChromaDB |
| **PDF Loader** | LangChain’s `PyPDFLoader` |
| **Environment** | Virtualenv / Pipenv |

**🏗️ Project Structure**


Chatbot-with-RAG<br>
│<br>
├── phase_1.py                 # Main Streamlit chatbot app<br>
├── data/                      # Folder to store your PDF files<br>
│   └── example.pdf<br>
├── Pipfile / requirements.txt # Dependencies (auto-generated by pipenv)<br>
├── README.md                  # Project documentation<br>
└── .env                       # Your environment variables (API keys)<br>


**⚙️ Setup Instructions**<br>


**1️⃣ Clone the Repository**<br>

git clone https://github.com/Ritika168/ChatBot-with-RAG.git

cd ChatBot-with-RAG

**2️⃣ Create Virtual Environment**

You can use either pipenv or venv.

Option A (Pipenv):

pip install pipenv
pipenv install
pipenv shell

Option B (venv):

python -m venv venv
venv\Scripts\activate     # for Windows
source venv/bin/activate  # for macOS/Linux
pip install -r requirements.txt<br>

**3️⃣ Add Your PDF**

Place your reference PDF inside the project folder or create a /data directory:

Chatbot-with-RAG/data/your_document.pdf


Update the path in phase_1.py:

pdf_name = "./data/your_document.pdf"<br>

**4️⃣ Add Your OpenAI API Key**

Create a .env file in the root directory:

OPENAI_API_KEY=your_api_key_here<br>

**▶️ Run the App**

Once setup is done, launch Streamlit:

streamlit run phase_1.py

The chatbot interface will open in your browser (usually at):

http://localhost:8501<br>


**📦 Dependencies**

Major libraries used:

streamlit
langchain
langchain-core
langchain-community
langgraph
chromadb
faiss-cpu
tiktoken
openai
pypdf
pandas
numpy
torch
transformers<br>

**💡 How It Works**

PDF Loading – The chatbot reads and extracts text using PyPDFLoader.

Text Chunking – Splits text into chunks for vector embedding.

Vectorization – Converts chunks into embeddings using HuggingFace models.

Storage – Stores embeddings in a ChromaDB (vector database).

Retrieval + Generation (RAG) – When you ask a question, it retrieves the top relevant chunks and sends them to the LLM to generate a context-aware answer.

